import time
from typing import Optional, Iterable, List, Tuple, Dict

import torch
import torch as th
from torch import Tensor
from tensordict.tensordict import TensorDict
from torchrl.envs.common import EnvBase
from torchrl.data import (
    BoundedTensorSpec,
    CompositeSpec,
    UnboundedContinuousTensorSpec,
    UnboundedDiscreteTensorSpec,
)
from rl4co.envs.common.base import RL4COEnvBase
from rl4co.envs.common.utils import Generator

# Modules
from environment.generator import MPP_Generator
from environment.utils import *

# Logger
from rl4co.utils.pylogger import get_pylogger
log = get_pylogger(__name__)

class MasterPlanningEnv(RL4COEnvBase):
    """Master Planning Problem (MPP) environment for Container Vessels Stowage Planning.

    Any episode in the MPP environment consists of |K|*|T| steps, where k \in K is set of cargo classes and \tau \in T
    is set of possible transports. The generator provides stochastic demand, where the agent only observes realized
    demand at the current ports. The future ports in the voyage are unknown, hence, the agent only observes the mean
    and std dev of the demand distribution. Hence, we define the initial embedding of the environment based on:
    - Cargo parameters:
        - POL: Ports of loading P = {0,1,...,|P|-1}
        - POD: Port of discharge P = {1,...,|P|}
        - cargo_class: Cargo classes K = {long_term, spot} \times {2 teus} \times {3 weights}
        - weight: Container weight in tonnes {1,2,3}
        - teu: Container Twenty-Foot-Equivalent units {1, 2}
        - revenue: Revenue generated by the container based on {long_term, spot} and distance between POL and POD
        # - discharge: Discharge flag (only first step of each port will discharge containers)
    - Demand distribution:
        - expected_demand: Expected demand of demand distribution
        - std_demand: Standard deviation of demand distribution

    At each step, the agent acts by loading containers characterized by (k,\tau) onto the vessel. The transitions are
    deterministic, i.e., containers are loaded and discharged based on the demand and vessel constraints. The reward
    The reward is computed based on the revenue generated by the loaded containers, as well as penalties for hatch
    overstowage. Furthermore, we have a set of constraints that the agent must satisfy, such as TEU capacity, cargo
    demand limit, stability limits (LCG,VCG), and the crane makespan limit.

    The environment has the following state variables: # todo: update this text!
    - Demand variables:
        - current_demand: Realized demand at time t
        - observed_demand: Observed demand at the current port

    - Vessel variables:
        - location utilization: Utilization of vessel locations at time t
        - clip_max: Residual TEU capacity of the vessel at time t
        - lhs_A: Left-hand side of the constraint matrix at time t
        - rhs: Right-hand side of the constraint matrix at time t
        - violation: Constraint violation of action at time t-1 (result of previous action)

    - Aggregated variables:
        - total_revenue: Total revenue during episode until time t
        - total_overstowage: Total hatch overstowage costs during episode until time t

    Compact formulation of constraints:
        Suppose we have a regular MIP in the form Ax <= b, where:
        - A:        constraint matrix of shape [n_constraints, B*D*K*T].
        - x:        Decision variable of MIP with shape [batch, B*D*K*T].
        - b:        Bound vector of shape [batch, n_constraints].

        Our policy is not the same shape as the MIP decision. We need to adjust the compact form to fit the policy.
        First, we rewrite x = x_t + x^{AC}.
        Second, we rewrite the constraints as A_t x_t <= b_t - Ax^{AC}, where:
        - x^{AC}:   Vessel's aggregated arrival condition of shape [batch, B*D**K*T].
        - x_t:      Policy output of shape [batch, B*D,].
        - A_t:      constraint matrix of shape [n_constraints, B*D].
        - b_t:      Bound vector of shape [batch, n_constraints].

        The compact form is used to compute the violation of the constraints for each action.
    """

    name = "mpp"

    def __init__(self, **kwargs):
        super().__init__()
        # Sets
        self.P = kwargs.get("ports") # Number of ports
        self.B = kwargs.get("bays")  # Number of bays
        self.D = kwargs.get("decks") # Number of decks
        self.T = int((self.P ** 2 - self.P) / 2) # Number of (POL,POD) transports
        self.CC = kwargs.get("customer_classes")  # Number of customer contracts
        self.K = kwargs.get("cargo_classes") * self.CC # Number of container classes
        self.W = kwargs.get("weight_classes")  # Number of weight classes

        # Init fns
        self.float_type = kwargs.get("float_type", th.float16)
        self.demand_uncertainty = kwargs.get("demand_uncertainty", False)
        self.generator = MPP_Generator(**kwargs)
        self._make_spec(self.generator)
        self._compact_form_shapes()
        self.zero = th.tensor([0], device=self.generator.device, dtype=self.float_type)
        self.padding = th.tensor([self.P-1], device=self.generator.device, dtype=th.int32)

        # Parameters:
        # Transport and cargo characteristics
        self.ports = torch.arange(self.P, device=self.generator.device)
        self.transport_idx = get_transport_idx(self.P, device=self.generator.device)
        self.transport_list = [(i,j) for i in range(self.P) for j in range(i+1, self.P)]
        # Step ordering: descending distance, longterm > spot; ascending TEU, ascending weight
        self.ordered_steps = self._precompute_step_ordering()
        self.k, self.tau = get_k_tau_pair(self.ordered_steps, self.K)
        self.pol, self.pod = get_pol_pod_pair(self.tau, self.P)
        self.k, self.tau, self.pol, self.pod = self._add_padding(self.k, self.tau, self.pol, self.pod)
        self.teus = th.arange(1, self.K // (self.CC * self.W) + 1, device=self.generator.device, dtype=self.float_type) \
            .repeat_interleave(self.W).repeat(self.CC)
        self.teus_episode = th.cat([self.teus.repeat(self.T), self.zero])
        self.weights = th.arange(1, self.W+1, device=self.generator.device, dtype=self.float_type).repeat(self.K//self.W)

        # Precomputes
        self._precompute_transport_sets()
        self._precompute_transport_sets_episode()
        self.next_port_mask = self._precompute_next_port_mask()
        self.transform_tau_to_pol = get_pols_from_transport(self.transport_idx, self.P, dtype=self.float_type)
        self.transform_tau_to_pod = get_pods_from_transport(self.transport_idx, self.P, dtype=self.float_type)

        # Capacity in TEU per location (bay,deck)
        c = kwargs.get("capacity")
        self.capacity = th.full((self.B, self.D,), c[0], device=self.generator.device, dtype=self.float_type)
        self.norm_capacity = self.capacity
        self.total_capacity = th.sum(self.capacity)

        # Revenue and costs
        self.revenues = self._precompute_revenues().view(-1)
        self.revenues = th.cat([self.revenues, self.padding])
        self.ho_costs = kwargs.get("hatch_overstowage_costs") #* th.mean(self.revenues)
        self.lc_costs = kwargs.get("long_crane_costs") #* th.mean(self.revenues)
        self.ho_mask = kwargs.get("hatch_overstowage_mask")

        # Crane intensity
        self.CI_target = kwargs.get("CI_target")

        # Stability
        self.stab_delta = kwargs.get("stability_difference")
        self.LCG_target = kwargs.get("LCG_target")
        self.VCG_target = kwargs.get("VCG_target")
        self.longitudinal_position = th.arange(1/self.B, self.B * 2/self.B, 2/self.B,
                                               device=self.generator.device, dtype=self.float_type)
        self.vertical_position = th.arange(1/self.D, self.D * 2/self.D, 2/self.D,
                                           device=self.generator.device, dtype=self.float_type)
        self.lp_weight = th.einsum("d, b -> bd", self.weights, self.longitudinal_position).unsqueeze(0)
        self.vp_weight = th.einsum("d, c -> cd", self.weights, self.vertical_position).unsqueeze(0)
        self.stability_params_lhs = self._precompute_stability_parameters()

        # Compact form:
        self.constraint_signs = th.tensor([1, 1, -1, 1, -1], device=self.generator.device, dtype=self.float_type)
        self.swap_signs_stability = th.tensor([1, -1, -1, -1, -1], device=self.generator.device, dtype=self.float_type)
        self.A = self._create_constraint_matrix(shape=(self.n_constraints, self.n_action, self.K, self.T))

    def _step(self, td: TensorDict) -> TensorDict:
        """Perform a step in the environment and return the next state."""
        # todo: perform gather_index for speed?

        ## Extraction and precompute
        action, lhs_A, rhs, t, batch_size = self._extract_from_td(td)
        pol, pod, k, tau, rev = self._extract_cargo_parameters_for_step(t[0])
        current_demand, realized_demand, utilization, target_long_crane, total_loaded, total_revenue, total_cost\
            = self._extract_from_state(td["state"])
        observed_demand, expected_demand, std_demand = self._extract_from_obs(td["obs"], batch_size)

        ## Current state
        # Check done, update utilization, and compute violation
        done = self._check_done(t)
        utilization = self._update_state_loading(action, utilization, k, tau,)
        violation = compute_violation(lhs_A, rhs, action, batch_size)

        # Compute overstowage
        pol_locations, pod_locations = self._compute_pol_pod_locations(utilization)
        agg_pol_location, agg_pod_location = self._aggregate_pol_pod_location(pol_locations, pod_locations)
        overstowage = self._compute_hatch_overstowage(utilization, pol)

        # Compute total_loaded and aggregated long crane excess
        total_loaded = total_loaded + th.min(action.sum(dim=(-2, -1)), current_demand)
        long_crane_moves = self._compute_long_crane(utilization, pol)
        excess_crane_moves = th.clamp(long_crane_moves - target_long_crane.view(-1, 1), min=0)

        ## Reward
        revenue = th.min(action.sum(dim=(-2, -1)), current_demand) * self.revenues[t[0]]
        profit = revenue.clone()
        if self.next_port_mask[t].any():
            ho_costs = overstowage.sum(dim=-1) * self.ho_costs
            lc_costs = excess_crane_moves.sum(dim=-1) * self.lc_costs
            cost = ho_costs + lc_costs
            profit -= (ho_costs + lc_costs)
        else:
            cost = th.zeros_like(profit)
        # (implemented outside environment with get_reward fn for code efficiency)
        # reward = th.zeros_like(t, dtype=self.float_type)

        ## Transition to next step
        # Update next state
        t = t + 1
        next_state_dict = self._update_next_state(utilization, target_long_crane,
                                                  realized_demand, observed_demand, expected_demand, std_demand, t,)
        # Update feasibility: lhs_A, rhs, clip_max based on next state
        utilization_ = next_state_dict["utilization"]
        lhs_A = self.create_lhs_A(lhs_A, t)
        rhs = self.create_rhs(utilization_, current_demand, batch_size)
        residual_capacity = th.clamp(self.norm_capacity - utilization_.sum(dim=-1) @ self.teus, min=self.zero) # teu

        # # Update action mask
        # # action_mask[t] = 0
        # mask_condition = (t[0] % self.K == 0)
        # min_pod = self._compute_min_pod(pol_locations, pod_locations )
        # new_mask = self._prevent_HO_mask(action_mask, pod, pod_locations, min_pod)
        # action_mask = th.where(mask_condition, new_mask, action_mask)

        # Only for final port: compute last port long crane excess
        if t[0] == self.K * self.T:
            # Compute last port long crane excess
            moves_bays_last_port = utilization.sum(dim=(2, 3, 4))
            lc_moves_last_port = (moves_bays_last_port[..., :-1] + moves_bays_last_port[..., 1:])
            lc_excess_last_port = th.clamp(lc_moves_last_port - next_state_dict["target_long_crane"].view(-1,1), min=0)

            # Compute metrics
            excess_crane_moves += lc_excess_last_port
            cost_ = lc_excess_last_port.sum(dim=-1) * self.lc_costs
            profit -= cost_
            cost += cost_

        # Track metrics and normalization
        total_revenue += revenue
        total_cost += cost
        # Normalize revenue based on highest possible step reward
        max_revenue = th.max(self.revenues) * th.max(realized_demand.view(-1, self.K*self.T), dim=1).values
        reward = profit / max_revenue # (total_revenue - total_cost) / self.total_capacity # profit per container
        scale_factor = self.teus_episode[t]

        # Update td output
        td.update({
            "state":{
                # Demand
                "current_demand": next_state_dict["current_demand"],

                # Vessel
                "utilization": next_state_dict["utilization"],
                "target_long_crane": next_state_dict["target_long_crane"],
                "agg_pol_location": agg_pol_location,
                "agg_pod_location": agg_pod_location,

                # Performance
                "total_loaded": total_loaded,
                "total_revenue": total_revenue,
                "total_cost": total_cost,
            },
            "obs":{
                # Demand
                "current_demand": next_state_dict["current_demand"],
                "observed_demand": next_state_dict["observed_demand"].view(*batch_size, self.K * self.T),
                "expected_demand": next_state_dict["expected_demand"].view(*batch_size, self.K * self.T),
                "std_demand": next_state_dict["std_demand"].view(*batch_size, self.K * self.T),
                "residual_capacity": residual_capacity.view(*batch_size, self.B * self.D),

                # Performance
                "total_loaded": total_loaded,
                "overstowage": overstowage,
                "excess_crane_moves": excess_crane_moves,
                "violation": violation,
            },

            # Feasibility and constraints
            "lhs_A": lhs_A,
            "rhs": rhs,
            "clip_max": residual_capacity.view(*batch_size, self.B*self.D),
            # Action, reward, done and step
            "action": action.view(*batch_size, self.B*self.D),
            "reward": reward,
            "profit": profit,
            "revenue": revenue,
            "cost": cost,
            "done": done,
            "episodic_step":t,
            "scale_factor": scale_factor,
        })
        return td

    def _reset(self,  td: Optional[TensorDict] = None,  batch_size=None) -> TensorDict:
        """Reset the environment to the initial state."""
        # # todo: with torchRL transformed, we need this
        # if batch_size is None:
        #     batch_size = [1] if td is None else td.batch_size
        # if td is None or td.is_empty():
        #     td = self.generator(batch_size=batch_size)
        # batch_size = [batch_size] if isinstance(batch_size, int) else batch_size
        # self.to(td.device)
        device = td.device

        # Initialize cargo parameters
        k = self.k[:-1].expand(*batch_size, -1)
        pol = self.pol[:-1].expand(*batch_size, -1)
        pod = self.pod[:-1].expand(*batch_size, -1)
        revenues = self.revenues[:-1].expand(*batch_size, -1)
        weights = self.weights[k]
        teus = self.teus[k]

        # Init state variables
        target_long_crane = self._compute_target_long_crane(td["realized_demand"], self.moves_idx[pol[0,0]])
        action_mask = th.ones((*batch_size, self.B, self.D), dtype=th.bool, device=device)
        locations_utilization = th.zeros((*batch_size, self.B, self.D,), device=device, dtype=self.float_type)
        clip_max = (self.norm_capacity / self.teus[k[0,0]]).unsqueeze(0).repeat(*batch_size, 1, 1)

        # Init obs + state
        initial_obs = TensorDict({
            # Demand
            "current_demand": td["observed_demand"][:, self.k[0], self.tau[0]],
            "observed_demand": td["observed_demand"].view(*batch_size, self.K * self.T),
            "expected_demand": td["expected_demand"].view(*batch_size, self.K * self.T),
            "std_demand": td["std_demand"].view(*batch_size, self.K * self.T),
            # Vessel
            "residual_capacity": clip_max.view(*batch_size, self.B*self.D),
            # "location_utilization": locations_utilization,
            # "location_weight": th.zeros_like(locations_utilization),
            # Performance
            "total_loaded": th.zeros_like(pol[:, 0], dtype=self.float_type),
            "overstowage": th.zeros((*batch_size, self.B,),  device=device, dtype=self.float_type),
            "excess_crane_moves": th.zeros((*batch_size, self.B-1,),  device=device, dtype=self.float_type),
            "violation": th.zeros((*batch_size, self.n_constraints), device=device, dtype=self.float_type),

        }, batch_size=batch_size, device=device,)


        initial_state = TensorDict({
            # Demand
            "current_demand": td["observed_demand"][:, self.k[0], self.tau[0]],
            "expected_demand": td["expected_demand"],
            "std_demand": td["std_demand"],
            "realized_demand": td["realized_demand"],

            # Vessel
            "utilization": th.zeros((*batch_size, self.B, self.D, self.K, self.T), device=device, dtype=self.float_type),
            "agg_pol_location": th.zeros_like(locations_utilization),
            "agg_pod_location": th.zeros_like(locations_utilization),
            "target_long_crane": target_long_crane,

            # Performance
            "total_loaded": th.zeros_like(pol[:, 0], dtype=self.float_type),
            "total_revenue": th.zeros_like(pol[:, 0], dtype=self.float_type),
            "total_cost": th.zeros_like(pol[:, 0], dtype=self.float_type),
        }, batch_size=batch_size, device=device,)

        # Init td
        t = th.zeros_like(pol[:,0], dtype=th.int64)
        _, _, moves_idx = self._precompute_for_step(pol[0,0])
        lhs_A = th.zeros((*batch_size, self.n_constraints, self.B * self.D),  device=device, dtype=self.float_type)
        lhs_A = self.create_lhs_A(lhs_A, t)
        rhs = self.create_rhs(initial_state["utilization"], initial_state["current_demand"], batch_size)
        reward = th.zeros_like(pol[:,0], dtype=self.float_type)
        td = TensorDict({
            # Cargo
            "POL": pol,
            "POD": pod,
            "cargo_class": k,
            "weight": weights,
            "TEU": teus,
            "revenue_parameter": revenues,

            # State + obs
            "state": initial_state,
            "obs": initial_obs,

            # Action mask and clipping
            "action": th.zeros_like(action_mask, dtype=self.float_type),
            "action_mask": action_mask.view(*batch_size, -1),
            "clip_min": th.zeros_like(clip_max, dtype=self.float_type).view(*batch_size, self.B*self.D, ),
            "clip_max": clip_max.view(*batch_size, self.B*self.D),
            "min_pod": th.zeros_like(clip_max, dtype=self.float_type),

            # Constraints
            "lhs_A": lhs_A,
            "rhs": rhs,

            # Reward, done and step
            "reward": reward,
            "profit": th.zeros_like(reward),
            "revenue": th.zeros_like(reward),
            "cost": th.zeros_like(reward),
            "done": th.zeros_like(pol[:,0], dtype=th.bool,),
            "episodic_step": t,

            # Scale factor (for next step)
            "scale_factor": self.teus_episode[t], #/self.total_capacity,
        }, batch_size=batch_size, device=device)
        return td

    def _make_spec(self, generator:Optional[Generator] = None) -> None:
        """Define the specs for observations, actions, rewards, and done flags."""
        self.observation_spec = CompositeSpec(
            observation=UnboundedContinuousTensorSpec(shape=(214)),  # Define shape as needed
        )
        self.obs_spec = TensorDict({
            'current_demand': torch.zeros(1, device=generator.device),
            'expected_demand': torch.zeros((self.K*self.T), device=generator.device),
            'std_demand': torch.zeros((self.K*self.T), device=generator.device),
            'observed_demand':torch.zeros((self.K*self.T), device=generator.device),
            'residual_capacity':torch.zeros((self.B*self.D), device=generator.device),
            'total_loaded': torch.zeros(1, device=generator.device),
            'overstowage': torch.zeros(self.B, device=generator.device),
            'excess_crane_moves': torch.zeros(self.B - 1, device=generator.device),
            'violation':torch.zeros(5, device=generator.device),
        }, batch_size=[])

        self.action_spec = BoundedTensorSpec(
            shape=(self.B*self.D),  # Define shape as needed
            low=0.0,
            high=10,  # Define high value as needed
        )
        self.reward_spec = UnboundedContinuousTensorSpec(shape=(1,))
        self.done_spec = UnboundedDiscreteTensorSpec(shape=(1,), dtype=th.bool)

    def check_solution_validity(self, td, actions) -> th.bool:
        """Check solution validity"""
        # todo: add validity logic
        return True

    def _check_done(self, t: Tensor) -> Tensor:
        """Determine if the episode is done based on the state."""
        return (t == (self.K * self.T) - 1)

    # Extraction functions
    def _extract_from_td(self, td) -> Tuple:
        """Extract action, reward and step from the TensorDict."""
        # Must clone to avoid in-place operations!
        batch_size = td.batch_size
        episodic_step = td["episodic_step"].clone()
        action = td["action"].clone().view(*batch_size, self.B, self.D,)
        # action_mask = td["action_mask"].clone()
        lhs_A = td["lhs_A"].clone()
        rhs = td["rhs"].clone()
        return action, lhs_A, rhs, episodic_step, batch_size
        # return action, action_mask, lhs_A, rhs,episodic_step, batch_size

    def _extract_cargo_parameters_for_step(self, t) -> Tuple:
        """Extract cargo-related parameters"""
        pol = self.pol[t]
        pod = self.pod[t]
        cargo_class = self.k[t]
        tau = self.tau[t]
        revenue = self.revenues[t]
        return pol, pod, cargo_class, tau, revenue

    def _extract_from_state(self, state) -> Tuple:
        """Extract and clone state variables from the state TensorDict."""
        # Demand-related variables
        current_demand = state["current_demand"].clone()
        realized_demand = state["realized_demand"].clone()
        # Vessel-related variables
        utilization = state["utilization"].clone()
        target_long_crane = state["target_long_crane"].clone()
        # # Additional variables
        total_loaded = state["total_loaded"].clone()
        total_revenue = state["total_revenue"].clone()
        total_cost = state["total_cost"].clone()
        # Return
        return current_demand, realized_demand, utilization, target_long_crane, total_loaded, total_revenue, total_cost

    def _extract_from_obs(self, obs, batch_size) -> Tuple:
        """Extract and clone state variables from the obs TensorDict."""
        observed_demand = obs["observed_demand"].clone().view(*batch_size, self.K, self.T)
        expected_demand = obs["expected_demand"].clone().view(*batch_size, self.K, self.T)
        std_demand = obs["std_demand"].clone().view(*batch_size, self.K, self.T)
        return observed_demand, expected_demand, std_demand

    # Reward/costs functions
    def _get_reward(self, td, utilizations) -> Tensor:
        """Compute total profit for episode"""
        metrics = self._get_metrics_n_step(td, utilizations)
        total_revenue = self._compute_total_revenue(metrics["actions"], metrics["realized_demand"])
        total_costs = self._compute_total_costs(metrics["total_overstowage"], metrics["total_excess_crane_moves"])
        return total_revenue - total_costs

    def _compute_total_revenue(self, actions, realized_demand) -> Tensor:
        """Compute total revenue during episode"""
        cargo = th.min(actions.sum(dim=(-1)), realized_demand[:,:,0,0].view(-1, self.K * self.T))
        return (cargo * self.revenues[:-1].view(1, -1,)).sum(dim=(-1)) # / self.total_capacity

    def _compute_total_costs(self, total_overstowage:Tensor, total_long_crane:Tensor) -> Tensor:
        """Compute total costs during episode"""
        return (total_overstowage * self.ho_costs + total_long_crane * self.lc_costs) # / self.total_capacity

    def _get_metrics_n_step(self, td, utilizations, actions=None) -> Dict:
        # ALlow for n_steps to be passed
        t = td["episodic_step"][0]
        n_steps = utilizations.shape[1]
        if utilizations.dim() == 2 or utilizations.dim() == 5:
            n_steps = 1
        # Reshape only once: [batch, n_steps, features]
        utilizations = utilizations.view(-1, n_steps, self.B, self.D, self.K, self.T)
        # todo: fix
        try:
            moves = self.moves_idx_episode[t-n_steps:t,:].view(1, n_steps, 1, 1, 1, self.T)
            ac_transport = self.remain_on_board_transport_episode[t - n_steps:t, :].view(1, n_steps, 1, 1, 1, self.T)
        except:
            moves = self.moves_idx_episode.view(1, n_steps, 1, 1, 1, self.T)
            ac_transport = self.remain_on_board_transport_episode.view(1, n_steps, 1, 1, 1, self.T)
        # todo: expand is expensive and should be avoided
        realized_demand = td["realized_demand"].view(-1, 1, self.K, self.T).expand(-1, n_steps, -1, -1)

        # Compute overstowage, target, and long crane moves in batches
        overstowage = self._compute_hatch_overstowage_n_step(utilizations, moves, ac_transport)
        target_long_crane = self._compute_target_long_crane_n_step(realized_demand, moves.view(1, n_steps, 1, self.T))
        long_crane_moves = self._compute_long_crane_n_step(utilizations, moves)
        # Compute long crane excess in-place to reduce memory operations
        lc_excess = th.clamp_(long_crane_moves - target_long_crane, min=0)

        # Sum overstowage and excess with mask applied in a single step
        mask = self.next_port_mask.view(1, -1, 1)
        total_overstowage = (overstowage * mask).sum(dim=(-2, -1))
        total_excess_crane_moves = ((lc_excess * mask.view(1, -1)).sum(dim=-1))

        # Compute last port long crane excess
        if t + n_steps >= self.K * self.T:
            moves_bays_last_port = td["state"]["utilization"].sum(dim=(2, 3, 4))
            long_crane_moves_last_port = (moves_bays_last_port[..., :-1] + moves_bays_last_port[..., 1:]).max(dim=-1).values
            target_last_port = td["state"]["target_long_crane"]
            lc_excess_last_port = th.clamp_(long_crane_moves_last_port - target_last_port, min=0)
            total_excess_crane_moves += lc_excess_last_port

        # Extract actions, permute only once and reuse the result
        if actions == None:
            actions = utilizations.max(dim=1).values.permute(0, 3, 4, 1, 2).view(-1, self.K * self.T, self.B * self.D)
            actions[:, -1] = td["action"].view(-1, self.B * self.D)

        return {
            "utilizations": utilizations,
            "actions": actions,
            "realized_demand": realized_demand,
            "total_loaded": actions.sum(dim=(-1, -2)),
            "total_overstowage": total_overstowage,
            "total_excess_crane_moves": total_excess_crane_moves,
        }

    def _compute_min_pod(self,pod_locations: Tensor) -> Tensor:
        """Compute min_pod based on utilization"""
        min_pod = th.argmax(pod_locations.to(self.float_type), dim=-1)
        min_pod[min_pod == 0] = self.P
        return min_pod

    def _compute_pol_pod_locations(self, utilization: Tensor) -> Tuple[Tensor, Tensor]:
        """Compute POL and POD locations based on utilization"""
        pol_locations = (utilization @ self.transform_tau_to_pol).sum(dim=-2) != 0
        pod_locations = (utilization @ self.transform_tau_to_pod).sum(dim=-2) != 0
        return pol_locations, pod_locations

    def _aggregate_pol_pod_location(self, pol_locations: Tensor, pod_locations: Tensor,) -> Tuple:
        """Aggregate pol_locations and pod_locations into:
            - pod: [max(pod_d0), min(pod_d1)]
            - pol: [min(pol_d0), max(pol_d1)]"""
        ## Get load indicators - we load below deck that is blocked
        # For above deck (d=0)
        min_pol_d0 = torch.where(pol_locations[:, :, 0, :] > 0, self.ports, self.P).min(dim=-1).values
        # For below deck (d=1):
        max_pol_d1 = torch.where(pol_locations[:, :, 1, :] > 0, self.ports, -1).max(dim=-1).values
        agg_pol_locations = torch.stack((min_pol_d0, max_pol_d1), dim=-1)

        ## Get discharge indicators - we discharge below deck that is blocked
        # For above deck (d=0):
        max_pod_d0 = torch.where(pod_locations[:, :, 0, :] > 0, self.ports, -1).max(dim=-1).values
        # For below deck (d=1):
        min_pod_d1 = torch.where(pod_locations[:, :, 1, :] > 0, self.ports, self.P).min(dim=-1).values
        agg_pod_locations = torch.stack((max_pod_d0, min_pod_d1), dim=-1)
        # Return indicators
        return agg_pol_locations.to(self.float_type), agg_pod_locations.to(self.float_type)

    def _compute_overstowage_loading_indicator(self, pod_locations: Tensor,) -> Tensor:
        """Indicate if overstowage is present due to discharge by: max(pod_d0) > min(pod_d1)
        Output: Positive integer tensor with shape [batch, bay, deck]"""
        # Get the number of pods
        pods = torch.arange(self.P, device=self.generator.device)
        # For above deck (d=0), compute the min POD index where value is 1 (non-zero elements)
        max_pod_d0 = torch.where(pod_locations[:, :, 0, :] > 0, pods, float('-inf')).max(dim=-1).values
        # For below deck (d=1), compute the max POD index where value is 1 (non-zero elements)
        min_pod_d1 = torch.where(pod_locations[:, :, 1, :] > 0, pods, float('inf')).min(dim=-1).values
        # Stack the results into the desired shape [batch, bay, 2]
        output = torch.stack((max_pod_d0, min_pod_d1), dim=-1)
        return output

    def _compute_hatch_overstowage(self, utilization: Tensor, single_pol: Tensor) -> Tensor:
        """Get hatch overstowage based on ac_transport and moves"""
        # Get indices
        ac_transport = self.remain_on_board_transport[single_pol]
        moves = self.moves_idx[single_pol]
        # Compute hatch overstowage
        hatch_open = utilization[:, :, 1:, :, moves].sum(dim=(2, 3, 4)) > 0
        hatch_overstowage = utilization[:, :, :1, :, ac_transport].sum(dim=(2, 3, 4)) * hatch_open
        return hatch_overstowage

    def _compute_target_long_crane(self, realized_demand: Tensor, moves: Tensor) -> Tensor:
        """Compute target crane moves per port:
        - Get total crane moves per port: load_moves + discharge_moves
        - Get optimal crane moves per adjacent bay by: 2 * total crane moves / B
        - Get adjacent capacity by: sum of capacity of adjacent bays
        - Get max capacity of adjacent bays by: max of adjacent capacity

        Return element-wise minimum of optimal crane moves and max capacity"""
        # Calculate optimal crane moves based per adjacent bay based on loading and discharging
        total_crane_moves = realized_demand[:, :, moves].sum(dim=(1,2))
        # Compute adjacent capacity and max capacity
        max_capacity = ((self.norm_capacity[:-1] + self.norm_capacity[1:]).sum(dim=-1)).max()
        # Compute element-wise minimum of crane moves and target long crane
        optimal_crane_moves_per_adj_bay = 2 * total_crane_moves / self.B
        return self.CI_target * th.minimum(optimal_crane_moves_per_adj_bay, max_capacity)

    def _compute_long_crane(self, utilization: Tensor, single_pol: Tensor) -> Tensor:
        """Compute costly long crane moves based on utilization and target long crane"""
        moves_idx = self.moves_idx[single_pol]
        moves_per_bay = (utilization @ moves_idx.to(utilization.dtype)).sum(dim=(2, 3))
        return moves_per_bay[:, :-1] + moves_per_bay[:, 1:]

    def _compute_hatch_overstowage_n_step(self, utilizations: Tensor, moves:Tensor, ac_transport: Tensor) -> Tensor:
        """Get hatch overstowage for n_steps"""
        # Compute hatch overstowage
        hatch_open = (utilizations[:, :, :, 1:, :, :] * moves).sum(dim=(3, 4, 5,)) > 0
        hatch_overstowage = (utilizations[:, :, :, :1, :, :] * ac_transport).sum(dim=(3, 4, 5)) * hatch_open
        return hatch_overstowage

    def _compute_target_long_crane_n_step(self, realized_demand: Tensor, moves:Tensor) -> Tensor:
        """Compute target crane moves for n_steps"""
        # Compute total crane moves and max capacity
        total_crane_moves = (realized_demand * moves).sum(dim=(-1, -2))
        max_capacity = ((self.norm_capacity[:, :-1] + self.norm_capacity[:, 1:]).sum(dim=-1)).max()
        # Compute element-wise minimum of target and max capacity
        optimal_crane_moves_per_adj_bay = 2 * total_crane_moves / self.B
        output = self.CI_target * th.minimum(optimal_crane_moves_per_adj_bay, max_capacity)
        return output

    def _compute_long_crane_n_step(self, utilizations: Tensor, moves:Tensor) -> Tensor:
        """Compute long crane moves per adjacent bay during episode"""
        # Compute long crane moves per adjacent bay
        long_crane_moves = (utilizations[:, :, :, :-1, :, :] * moves).sum(dim=(3, 4, 5))
        adj_bays =  long_crane_moves[..., :-1] + long_crane_moves[..., 1:]
        return adj_bays.max(dim=-1).values

    def _prevent_HO_mask(self, mask:Tensor, pod: Tensor,pod_locations:Tensor, min_pod:Tensor) -> Tensor:
        """
        Mask action to prevent hatch overstowage. Deck indices: 0 is above-deck, 1 is below-deck.

        Variables:
            - Utilization: Current state of onboard cargo (bay,deck,cargo_class,transport)
            - POD_locations: Indicator to show PODs loaded in locations (bay,deck,P)
            - Min_pod: Minimum POD location based on POD_locations (bay,deck)

        Utilization is filled/emptied incrementally. Hence, we have certain circumstances to observe utilization:
            - Step after reset: Utilization is empty
            - Step of new POL:  Discharge utilization destined for new POL
            - Any other step:   Load utilization of current cargo_class and transport

        Two ways to prevent hatch overstowage:
        - If above-deck is empty, we can freely place below-deck. Otherwise, we need to restow above-deck directly.
            E.g.:
                    | 3 | 3 | o |
                    +---+---+---+
                    | x | x | o |   , where int is min_pod of location, x is blocked location, o is open location

        - Above-deck actions are allowed if current POD <= min_pod below-deck. Otherwise, we need to restow
            above-deck when below-deck will be discharged.
            E.g.:   POD = 2
                    | x | o | o |
                    +---+---+---+
                    | 1 | 2 | 3 |   , where int is min_pod of location, x is blocked location, o is open location
        """
        # Create mask:
        mask = mask.view(-1, self.B, self.D)
        # Action below-deck (d=1) allowed if above-deck (d=0) is empty
        mask[:, :, 1] = pod_locations[:, :, 0, :].sum(dim=-1) == 0
        # Action above-deck (d=0) allowed if POD <= min_pod below deck (d=1)
        mask[:, :, 0] = pod.unsqueeze(-1) <= min_pod[:, :, 1]
        return mask.view(-1, self.B*self.D)

    # Update state
    def _update_state_discharge(self, utilization:Tensor, disc_idx:Tensor,) -> Tensor:
        """Update state as result of discharge"""
        utilization[:, :, :, :, disc_idx] = 0.0
        return utilization

    def _update_state_loading(self, action: Tensor, utilization: Tensor,
                              k:Tensor, tau:Tensor) -> Tensor:
        """Transition to the next state based on the action."""
        new_utilization = utilization.clone().view(-1, self.B, self.D, self.K, self.T)
        new_utilization[:, :, :, k, tau] = action
        return new_utilization

    def _update_next_state(self, utilization: Tensor, target_long_crane:Tensor, realized_demand:Tensor,
                           observed_demand:Tensor, expected_demand:Tensor, std_demand:Tensor, t:Tensor,) \
            -> Dict[str, Tensor]:
        """Update next state, following options:
        - Next step moves to new port POL+1
        - Next step moves to new transport (POL, POD-1)
        - Last step of episode; compute crane violation at last port
        """
        # Get cargo parameters
        pol, pod, k, tau, _ = self._extract_cargo_parameters_for_step(t[0])

        # Check next port with t - 1
        load_idx, disc_idx, moves_idx = self._precompute_for_step(pol)
        # Next port with discharging; Update utilization, observed demand and target long crane
        if self.next_port_mask[t-1].any():
            utilization = self._update_state_discharge(utilization, disc_idx)
            target_long_crane = self._compute_target_long_crane(realized_demand, moves_idx)
            if self.demand_uncertainty:
                observed_demand[:, :, load_idx] = realized_demand[:, :, load_idx]

        # Update observed and expected demand by setting to 0
        observed_demand[:, k, tau] = 0
        expected_demand[:, k, tau] = 0
        std_demand[:, k, tau] = 0

        # Get output
        return {
            "current_demand": realized_demand[:, k, tau],
            "observed_demand": observed_demand,
            "expected_demand": expected_demand,
            "std_demand":std_demand,
            "utilization": utilization,
            "location_utilization": (utilization * self.teus.view(1,1,1,-1,1)).sum(dim=(-2,-1)),
            "location_weight": (utilization * self.weights.view(1, 1, 1, -1, 1)).sum(dim=(-1,-2)),
            "target_long_crane": target_long_crane,
        }

    # Compact formulation
    def _compact_form_shapes(self, ):
        """Define shapes for compact form"""
        self.n_demand = 1
        self.n_stability = 4
        # self.n_cranes = self.B - 1
        self.n_action = self.B * self.D
        self.n_constraints = self.n_demand + self.n_stability #+ self.n_cranes

    def _create_constraint_matrix(self, shape: Tuple[int, int, int, int], ):
        """Create constraint matrix A for compact constraints Au <= b"""
        # [1, LM-TW, TW-LM, VM-TW, TW-VM]
        A = th.ones(shape, device=self.generator.device, dtype=self.float_type)
        A *= self.constraint_signs.view(-1, 1, 1, 1)
        A[self.n_demand:self.n_demand + self.n_stability] *= self.stability_params_lhs.view(self.n_stability, self.B*self.D, self.K, 1)
        return A.view(self.n_constraints, self.B*self.D, -1)

    def create_lhs_A(self, lhs_A:Tensor, t:Tensor) -> Tensor:
        """Create lhs A_t of compact constraints: A_t x_t <= b_t"""
        lhs_A[:] = self.A[:,:, t[0]-1].clone()
        return lhs_A

    def create_rhs(self, utilization:Tensor, current_demand:Tensor, batch_size) -> Tensor:
        """Create rhs of compact constraints: A_t x_t <= b_t"""
        # Get rhs = [current_demand, LM_ub, LM_lb, VM_ub, _VM_lb]
        # Stability constraints
        A = self.swap_signs_stability.view(-1, 1, 1,) * self.A.clone()
        rhs = utilization.view(*batch_size, -1) @ A.view(self.n_constraints, -1).T
        # Demand constraint
        rhs[:, :self.n_demand] = current_demand.view(-1, 1)
        return rhs

    # Precomputes
    def _precompute_step_ordering(self):
        """Get ordered steps with transports in descending order of distance
        Suppose (k,tau) = (k, (POL,POD), then we have the following ordered set:
        { (0, (0,P-1)), (1, (0,P-1)), ..., (K-1, (0,P-1));
          (0, (0,P-2)), (1, (0,P-2)), ..., (K-1, (0,P-2));
          ...
          (0, (1,P-1)), (1, (1,P-1)), ..., (K-1, (1,P-1));
          (0, (1,P-2)), (1, (1,P-2)), ..., (K-1, (1,P-2));
          ...
          (0, (P-2,P-1)), (1, (P-2,P-1)), ..., (K-1, (P-2,P-1)) }
        """
        # Initialize steps and idx
        steps = th.zeros(self.K*self.T, dtype=th.int64, device=self.generator.device)
        idx = 0
        # We use loops for readability and simplicity, only because it is part of initialization
        for pol in range(self.P - 1):
            for pod in range(self.P - 1, pol, -1):
                # Get the transport index of (POL,POD)
                tau = get_transport_from_pol_pod(pol, pod, self.transport_idx)
                # Create a range of k values for this combination and store the result
                steps[idx:idx + self.K] = th.arange(self.K, device=self.generator.device, dtype=self.float_type) + tau * self.K
                idx += self.K
        return steps

    def _add_padding(self, *inputs) -> List[Tensor]:
        """For any number of inputs, add a zero padding at the end of vector"""
        output = []
        for input_tensor in inputs:
            padded_tensor = th.cat([input_tensor, self.padding])
            output.append(padded_tensor)
        return output

    def _precompute_for_step(self, pol:Tensor) -> Tuple[Tensor,Tensor,Tensor]:
        """Precompute variables and index masks for the current step"""
        # Index masks
        load_idx = self.load_transport[pol]
        disc_idx = self.discharge_transport[pol]
        moves_idx = self.moves_idx[pol]
        return load_idx, disc_idx, moves_idx

    def _precompute_revenues(self, reduce_long_revenue=0.3) -> Tensor:
        """Precompute matrix of revenues with shape [K, T]"""
        # Initialize revenues and pod_grid
        revenues = th.zeros((self.K, self.P, self.P), device=self.generator.device, dtype=self.float_type) # Shape: [K, P, P]
        pod = th.arange(self.P, 0, -1, device=self.generator.device, dtype=self.float_type)  # Shape: [P]
        _, pod_grid = th.meshgrid(th.zeros_like(pod), pod, indexing='ij')  # Shapes: [P, P]
        pod_grid = pod_grid.to(revenues.dtype)
        # Compute revenues
        mask = th.arange(self.K, device=self.generator.device, dtype=self.float_type) < self.K // 2 # Spot/long-term mask
        revenues[~mask] = pod_grid # Spot market contracts
        revenues[mask] = (pod_grid * (1 - reduce_long_revenue)) # Long-term contracts
        i, j = th.triu_indices(self.P, self.P, offset=1) # Get above-diagonal indices of revenues
        # Add 0.1 for variable revenue per container, regardless of (k,tau)
        output = revenues[:, i, j] + 0.1 # Shape: [K, T], where T = P*(P-1)/2
        return output.T.reshape(-1) # Shape: [T*K]

    def _precompute_transport_sets(self):
        """Precompute transport sets based on POL with shape(s): [P, T]"""
        # Note: transport sets in the environment do not depend on batches for efficiency.
        # Hence, implementation only works for batches with the same episodic step (e.g., single-step MDP)

        # Get transport sets for demand
        p = th.arange(self.P, device=self.generator.device, dtype=self.float_type).view(-1,1)
        self.load_transport = get_load_transport(self.transport_idx, p)
        self.previous_load_transport = get_load_transport(self.transport_idx, p-1)
        self.discharge_transport = get_discharge_transport(self.transport_idx, p)
        self.not_on_board_transport = get_not_on_board_transport(self.transport_idx, p)
        self.remain_on_board_transport = get_remain_on_board_transport(self.transport_idx, p)
        self.moves_idx = self.load_transport + self.discharge_transport

    def _precompute_transport_sets_episode(self):
        """Precompute transport sets based on POL with shape(s): [Seq, T]"""
        # Get transport sets for demand
        pol_t = self.pol[:-1].view(-1,1)
        self.load_transport_episode = get_load_transport(self.transport_idx, pol_t)
        self.previous_load_transport_episode = get_load_transport(self.transport_idx, pol_t-1)
        self.discharge_transport_episode = get_discharge_transport(self.transport_idx, pol_t)
        self.not_on_board_transport_episode = get_not_on_board_transport(self.transport_idx, pol_t)
        self.remain_on_board_transport_episode = get_remain_on_board_transport(self.transport_idx, pol_t)
        self.moves_idx_episode = self.load_transport_episode + self.discharge_transport_episode

    def _precompute_next_port_mask(self):
        """Precompute next port based on POL with shape: [P, T]
        - Next port happens when POD = POL+1
        """
        # Initialize next_port
        next_port = th.zeros((self.K*self.T), dtype=th.bool, device=self.generator.device)
        pol_values = th.arange(self.P - 1, 0, -1,)  # POL values from P-1 to 1
        indices = th.cumsum(self.K * pol_values, dim=0) - 1
        next_port[indices] = True
        return next_port

    def _precompute_stability_parameters(self,):
        """Precompute lhs stability parameters for compact constraints. Get rhs by negating lhs."""
        lp_weight = self.lp_weight.unsqueeze(2).expand(-1,-1,self.D,-1)
        vp_weight = self.vp_weight.unsqueeze(1).expand(-1,self.B,-1,-1)
        p_weight = th.cat([lp_weight, lp_weight, vp_weight, vp_weight], dim=0)
        target = torch.tensor([self.LCG_target, self.LCG_target, self.VCG_target, self.VCG_target],
                              device=self.generator.device, dtype=self.float_type).view(-1,1,1,1)
        delta = torch.tensor([self.stab_delta, -self.stab_delta, self.stab_delta, -self.stab_delta],
                             device=self.generator.device, dtype=self.float_type).view(-1,1,1,1)
        output = p_weight - self.weights.view(1,1,1,self.K) * (target + delta)
        return output.view(-1, self.B*self.D, self.K,)